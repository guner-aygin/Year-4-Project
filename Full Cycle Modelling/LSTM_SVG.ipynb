{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec39fb3f-0be8-45db-85a3-b1212b10f18d",
   "metadata": {},
   "source": [
    "# LSTM for Smoothed Sunspot Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baae640-b0c5-49e9-891c-ade48d2df4bf",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "Initially started using an RNN with a ReLu activation function, which produced some form of results, but they didn't fit well to the data.\n",
    "\n",
    "I also attempted to use a Sigmoid function & Elu function instead, which seemed to perform worse than the Relu activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e262a69-e869-463a-8a39-d05a937e127c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 09:22:14.691979: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82445405-11db-4268-890e-ade5526d5fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sunspot_Number</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1818.001</th>\n",
       "      <td>34.566570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818.004</th>\n",
       "      <td>34.546053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818.007</th>\n",
       "      <td>34.525535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818.010</th>\n",
       "      <td>34.505017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818.012</th>\n",
       "      <td>34.484499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sunspot_Number\n",
       "Year                    \n",
       "1818.001       34.566570\n",
       "1818.004       34.546053\n",
       "1818.007       34.525535\n",
       "1818.010       34.505017\n",
       "1818.012       34.484499"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/SVG_poly1.csv') # importing data for SVG polyorder = 1\n",
    "X = ((df.Year).values).reshape(-1,1)\n",
    "y = (df.Sunspot_Number).values\n",
    "yerr = np.zeros(len(X))\n",
    "\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True) \n",
    "# removes the unnecessary column\n",
    "df.set_index(\"Year\", inplace=True)\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788363be-7f60-4c6c-8099-79a2e9a7ee8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "201ade13-5a48-4c1b-bf5f-7d6b57ae90f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 70000\n",
    "skips = 28 # 1 data point per luna cycle\n",
    "train_data = df.iloc[:limit:skips] \n",
    "validation_data = df.iloc[limit::skips]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19c907a1-00a2-46da-a5b3-8ddb4f72204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfc70b68-7400-4023-943c-84ebfa249940",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(train_data)\n",
    "scaled_train = scaler.transform(train_data)\n",
    "scaled_test = scaler.transform(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46b360bd-f40b-484c-b486-eb08f1d529c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0f8c7d9-c1f9-4767-b179-73c76a68df3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generator\n",
    "n_input = 11 * 12 # 11 years \n",
    "n_features = 1 # we are only using 1 timeseries to make our predictions\n",
    "generator = TimeseriesGenerator(scaled_train, scaled_train, length=n_input, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "304f2642-1efd-4ffe-ac4d-a0a461eb3d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = generator[0]\n",
    "#print(f'Given the Array: \\n{X.flatten()}')\n",
    "#print(f'Predict this y: \\n {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fec8f90-8c99-4347-98aa-e9213d8af1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c01a358a-bea8-4a9b-8f29-697433c8072c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 300)               362400    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 301       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 362,701\n",
      "Trainable params: 362,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 09:22:18.961837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# define model\n",
    "model = Sequential() # adds layers in a sequence\n",
    "model.add(LSTM(300, activation='relu', input_shape=(n_input, n_features))) # maybe try elu?\n",
    "# 100 neurons\n",
    "model.add(Dense(1))\n",
    "# 1 layer\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='mse')\n",
    "# smaller learning rate = longer running time\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d6394a-eaa0-4232-a9a9-d4e93c3bf307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2368/2368 [==============================] - 128s 53ms/step - loss: 0.0323\n",
      "Epoch 2/100\n",
      "2368/2368 [==============================] - 160s 68ms/step - loss: 0.0017\n",
      "Epoch 3/100\n",
      "2368/2368 [==============================] - 141s 60ms/step - loss: 7.0800e-04\n",
      "Epoch 4/100\n",
      "2368/2368 [==============================] - 129s 55ms/step - loss: 3.2560e-04\n",
      "Epoch 5/100\n",
      "2368/2368 [==============================] - 130s 55ms/step - loss: 2.2254e-04\n",
      "Epoch 6/100\n",
      "2368/2368 [==============================] - 121s 51ms/step - loss: 1.8142e-04\n",
      "Epoch 7/100\n",
      "2368/2368 [==============================] - 140s 59ms/step - loss: 1.6510e-04\n",
      "Epoch 8/100\n",
      "2368/2368 [==============================] - 137s 58ms/step - loss: 1.5355e-04\n",
      "Epoch 9/100\n",
      "2368/2368 [==============================] - 136s 58ms/step - loss: 1.4330e-04\n",
      "Epoch 10/100\n",
      "2368/2368 [==============================] - 143s 60ms/step - loss: 1.3394e-04\n",
      "Epoch 11/100\n",
      "2368/2368 [==============================] - 146s 62ms/step - loss: 1.2274e-04\n",
      "Epoch 12/100\n",
      "2368/2368 [==============================] - 145s 61ms/step - loss: 1.1885e-04\n",
      "Epoch 13/100\n",
      "2368/2368 [==============================] - 145s 61ms/step - loss: 1.0925e-04\n",
      "Epoch 14/100\n",
      "2368/2368 [==============================] - 146s 62ms/step - loss: 1.0413e-04\n",
      "Epoch 15/100\n",
      "2368/2368 [==============================] - 146s 62ms/step - loss: 9.8043e-05\n",
      "Epoch 16/100\n",
      "2368/2368 [==============================] - 146s 62ms/step - loss: 9.2361e-05\n",
      "Epoch 17/100\n",
      "2368/2368 [==============================] - 147s 62ms/step - loss: 9.0431e-05\n",
      "Epoch 18/100\n",
      "2368/2368 [==============================] - 146s 62ms/step - loss: 8.7658e-05\n",
      "Epoch 19/100\n",
      "2368/2368 [==============================] - 136s 57ms/step - loss: 8.4405e-05\n",
      "Epoch 20/100\n",
      "2368/2368 [==============================] - 128s 54ms/step - loss: 8.2863e-05\n",
      "Epoch 21/100\n",
      "2368/2368 [==============================] - 133s 56ms/step - loss: 7.9975e-05\n",
      "Epoch 22/100\n",
      "2368/2368 [==============================] - 134s 57ms/step - loss: 7.8768e-05\n",
      "Epoch 23/100\n",
      "2368/2368 [==============================] - 131s 56ms/step - loss: 7.6686e-05\n",
      "Epoch 24/100\n",
      "2368/2368 [==============================] - 133s 56ms/step - loss: 7.2840e-05\n",
      "Epoch 25/100\n",
      "2368/2368 [==============================] - 138s 58ms/step - loss: 7.3430e-05\n",
      "Epoch 26/100\n",
      "2368/2368 [==============================] - 173s 73ms/step - loss: 7.1204e-05\n",
      "Epoch 27/100\n",
      "2368/2368 [==============================] - 255s 108ms/step - loss: 6.9937e-05\n",
      "Epoch 28/100\n",
      "2368/2368 [==============================] - 254s 107ms/step - loss: 6.8342e-05\n",
      "Epoch 29/100\n",
      "2368/2368 [==============================] - 210s 89ms/step - loss: 6.7015e-05\n",
      "Epoch 30/100\n",
      "2368/2368 [==============================] - 146s 62ms/step - loss: 6.5631e-05\n",
      "Epoch 31/100\n",
      "2368/2368 [==============================] - 182s 77ms/step - loss: 6.5005e-05\n",
      "Epoch 32/100\n",
      "2368/2368 [==============================] - 217s 92ms/step - loss: 6.2402e-05\n",
      "Epoch 33/100\n",
      "2368/2368 [==============================] - 195s 82ms/step - loss: 6.2473e-05\n",
      "Epoch 34/100\n",
      "2368/2368 [==============================] - 244s 103ms/step - loss: 6.3185e-05\n",
      "Epoch 35/100\n",
      "2368/2368 [==============================] - 258s 109ms/step - loss: 6.1690e-05\n",
      "Epoch 36/100\n",
      "2368/2368 [==============================] - 230s 97ms/step - loss: 5.9599e-05\n",
      "Epoch 37/100\n",
      "2368/2368 [==============================] - 141s 59ms/step - loss: 5.9421e-05\n",
      "Epoch 38/100\n",
      "2368/2368 [==============================] - 155s 65ms/step - loss: 5.8501e-05\n",
      "Epoch 39/100\n",
      "2368/2368 [==============================] - 238s 100ms/step - loss: 5.8001e-05\n",
      "Epoch 40/100\n",
      "2368/2368 [==============================] - 236s 100ms/step - loss: 5.7487e-05\n",
      "Epoch 41/100\n",
      "2368/2368 [==============================] - 243s 103ms/step - loss: 5.5184e-05\n",
      "Epoch 42/100\n",
      "2368/2368 [==============================] - 255s 108ms/step - loss: 5.4344e-05\n",
      "Epoch 43/100\n",
      "2368/2368 [==============================] - 143s 60ms/step - loss: 5.3563e-05\n",
      "Epoch 44/100\n",
      "2368/2368 [==============================] - 148s 62ms/step - loss: 5.4384e-05\n",
      "Epoch 45/100\n",
      "2368/2368 [==============================] - 147s 62ms/step - loss: 5.3466e-05\n",
      "Epoch 46/100\n",
      "2368/2368 [==============================] - 166s 70ms/step - loss: 5.3423e-05\n",
      "Epoch 47/100\n",
      "2368/2368 [==============================] - 233s 98ms/step - loss: 5.2939e-05\n",
      "Epoch 48/100\n",
      "2368/2368 [==============================] - 240s 101ms/step - loss: 5.1679e-05\n",
      "Epoch 49/100\n",
      "2368/2368 [==============================] - 263s 111ms/step - loss: 5.0996e-05\n",
      "Epoch 50/100\n",
      "2368/2368 [==============================] - 250s 105ms/step - loss: 5.0054e-05\n",
      "Epoch 51/100\n",
      "2368/2368 [==============================] - 155s 65ms/step - loss: 5.0041e-05\n",
      "Epoch 52/100\n",
      "2368/2368 [==============================] - 177s 75ms/step - loss: 4.9375e-05\n",
      "Epoch 53/100\n",
      "2368/2368 [==============================] - 149s 63ms/step - loss: 4.7921e-05\n",
      "Epoch 54/100\n",
      "2368/2368 [==============================] - 134s 57ms/step - loss: 4.9071e-05\n",
      "Epoch 55/100\n",
      "2368/2368 [==============================] - 167s 71ms/step - loss: 4.7180e-05\n",
      "Epoch 56/100\n",
      "2368/2368 [==============================] - 230s 97ms/step - loss: 4.7430e-05\n",
      "Epoch 57/100\n",
      "2368/2368 [==============================] - 199s 84ms/step - loss: 4.7464e-05\n",
      "Epoch 58/100\n",
      "2368/2368 [==============================] - 138s 58ms/step - loss: 4.6965e-05\n",
      "Epoch 59/100\n",
      "2368/2368 [==============================] - 143s 60ms/step - loss: 4.6297e-05\n",
      "Epoch 60/100\n",
      "2368/2368 [==============================] - 188s 79ms/step - loss: 4.6646e-05\n",
      "Epoch 61/100\n",
      "2368/2368 [==============================] - 237s 100ms/step - loss: 4.4530e-05\n",
      "Epoch 62/100\n",
      "2368/2368 [==============================] - 224s 95ms/step - loss: 4.3597e-05\n",
      "Epoch 63/100\n",
      "2368/2368 [==============================] - 150s 63ms/step - loss: 4.4326e-05\n",
      "Epoch 64/100\n",
      "2368/2368 [==============================] - 164s 69ms/step - loss: 4.3442e-05\n",
      "Epoch 65/100\n",
      "2368/2368 [==============================] - 200s 84ms/step - loss: 4.2986e-05\n",
      "Epoch 66/100\n",
      "2368/2368 [==============================] - 246s 104ms/step - loss: 4.4210e-05\n",
      "Epoch 67/100\n",
      "  88/2368 [>.............................] - ETA: 3:59 - loss: 3.8999e-05"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "epochs = 100\n",
    "\n",
    "# Define a ModelCheckpoint callback to save the model weights based on validation loss\n",
    "#checkpoint = ModelCheckpoint('best_weights.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# Fit the model to the data, using the ModelCheckpoint callback\n",
    "history = model.fit(generator, epochs=epochs, batch_size=1) #validation_data=(scaled_test,scaled_test), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de699997-b427-4a5c-8508-4a4262bf2226",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_per_epoch = model.history.history['loss']\n",
    "#val_loss_per_epoch = model.history.history['val_loss']\n",
    "plt.plot(range(len(loss_per_epoch)),loss_per_epoch);\n",
    "#plt.plot(range(len(val_loss_per_epoch)), val_loss_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027cad75-5bc7-4aed-9b61-e253e7ac61c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_train_batch = scaled_train[-n_input:] \n",
    "# take the last n_input month of values, to make \n",
    "# predictions on the 1st test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c36497-2d27-49ee-99d0-5f17aeb01b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_train_batch = last_train_batch.reshape((1, n_input, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2827ecc5-7f07-4bce-9367-9e7300026262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.predict(last_train_batch)\n",
    "\n",
    "y_pred = model.predict(generator)\n",
    "\n",
    "st = scaled_train.shape[0]\n",
    "yp = y_pred.shape[0]\n",
    "c = st - yp\n",
    "# Note: predictions start after 'n_input' numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e934267-9323-443b-bf02-7ee1ed36d242",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(c, st), y_pred, label='predict') \n",
    "plt.plot(scaled_train, label='train')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e33c08-0dce-4a30-b805-40be960c148d",
   "metadata": {},
   "source": [
    "#### Comment on plot:\n",
    "\n",
    "The above plot shows how well our model fits with the training data. As the orange and blue lines almost completely overlap, we can conclude that the model accurately fits with the data. This is a necessary check, as our model will have no chance of predicting future sunspot numbers if it cannot successfully predict the training values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a534f6-9e5e-44f1-af70-7b379daee63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_predictions = []\n",
    "\n",
    "first_eval_batch = scaled_train[-n_input:]\n",
    "current_batch = first_eval_batch.reshape((1, n_input, n_features))\n",
    "\n",
    "for i in range(len(validation_data)):\n",
    "    \n",
    "    # get the prediction value for the first batch\n",
    "    current_pred = model.predict(current_batch)[0]\n",
    "    \n",
    "    # append the prediction into the array\n",
    "    validation_predictions.append(current_pred) \n",
    "    \n",
    "    # use the prediction to update the batch and remove the first value\n",
    "    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787881a8-d5ab-42b6-8403-302b605fe40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_predictions\n",
    "# NOTE: these predictions are in the range 0-1\n",
    "# we need to convert it back "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c1f186-6cc9-4993-83df-16cae238fc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_predictions = scaler.inverse_transform(validation_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee137c3-91f5-454e-a4cf-fb9e73275afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data['Predictions'] = true_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f1e22-3adb-426a-82e3-f45ce5e004a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data.plot(figsize=(14,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb01a206-0ccc-419c-bb67-ba52320f2a53",
   "metadata": {},
   "source": [
    "#### Comment on plot:\n",
    "\n",
    "The predictions for future sunspot number seem to have a period which is close to the observed period (but not perfect), and the amplitude is still too high. I can try running again with more epochs or more neurons and see what happens.\n",
    "\n",
    "**Edit**: run with 300 neurons produced a similar result to one with 200 neurons. Next I will try running with 200 neurons again, but for 100 epochs.\n",
    "\n",
    "**Edit 2**: run with 200 neurons for 87 epochs produced results with a smaller amplitude, but the timing of the peaks were incorrect."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
