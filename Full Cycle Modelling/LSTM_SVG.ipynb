{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec39fb3f-0be8-45db-85a3-b1212b10f18d",
   "metadata": {},
   "source": [
    "# LSTM for Smoothed Sunspot Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baae640-b0c5-49e9-891c-ade48d2df4bf",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "Initially started using an RNN with a ReLu activation function, which produced some form of results, but they didn't fit well to the data.\n",
    "\n",
    "I also attempted to use a Sigmoid function & Elu function instead, which seemed to perform worse than the Relu activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e262a69-e869-463a-8a39-d05a937e127c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 13:56:31.243513: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82445405-11db-4268-890e-ade5526d5fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sunspot_Number</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1818.001</th>\n",
       "      <td>34.566570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818.004</th>\n",
       "      <td>34.546053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818.007</th>\n",
       "      <td>34.525535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818.010</th>\n",
       "      <td>34.505017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818.012</th>\n",
       "      <td>34.484499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sunspot_Number\n",
       "Year                    \n",
       "1818.001       34.566570\n",
       "1818.004       34.546053\n",
       "1818.007       34.525535\n",
       "1818.010       34.505017\n",
       "1818.012       34.484499"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/SVG_poly1.csv') # importing data for SVG polyorder = 1\n",
    "X = ((df.Year).values).reshape(-1,1)\n",
    "y = (df.Sunspot_Number).values\n",
    "yerr = np.zeros(len(X))\n",
    "\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True) \n",
    "# removes the unnecessary column\n",
    "df.set_index(\"Year\", inplace=True)\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788363be-7f60-4c6c-8099-79a2e9a7ee8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "201ade13-5a48-4c1b-bf5f-7d6b57ae90f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 70000\n",
    "skips = 28 # 1 data point per luna cycle\n",
    "train_data = df.iloc[:limit:skips] \n",
    "validation_data = df.iloc[limit::skips]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19c907a1-00a2-46da-a5b3-8ddb4f72204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfc70b68-7400-4023-943c-84ebfa249940",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(train_data)\n",
    "scaled_train = scaler.transform(train_data)\n",
    "scaled_test = scaler.transform(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46b360bd-f40b-484c-b486-eb08f1d529c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0f8c7d9-c1f9-4767-b179-73c76a68df3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generator\n",
    "n_input = 11 * 12 # 11 years \n",
    "n_features = 1 # we are only using 1 timeseries to make our predictions\n",
    "generator = TimeseriesGenerator(scaled_train, scaled_train, length=n_input, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "304f2642-1efd-4ffe-ac4d-a0a461eb3d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = generator[0]\n",
    "#print(f'Given the Array: \\n{X.flatten()}')\n",
    "#print(f'Predict this y: \\n {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fec8f90-8c99-4347-98aa-e9213d8af1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c01a358a-bea8-4a9b-8f29-697433c8072c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 132, 100)          40800     \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 50)                30200     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71,051\n",
      "Trainable params: 71,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential() # adds layers in a sequence\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_input, n_features))) # maybe try elu?\n",
    "# 300 neurons, return_sequences=True to add more LSTM layers\n",
    "model.add(LSTM(50, activation='relu')) # 150 neurons\n",
    "#model.add(LSTM(75, activation='relu')) # 75 neurons\n",
    "#model.add(Dense(50, activation='relu')) # additional Dense layer with 50 neurons\n",
    "model.add(Dense(1))\n",
    "# 1 layer\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='mse')\n",
    "# smaller learning rate = longer running time\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d6394a-eaa0-4232-a9a9-d4e93c3bf307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2368/2368 [==============================] - 295s 124ms/step - loss: 0.0469\n",
      "Epoch 2/50\n",
      "2368/2368 [==============================] - 267s 113ms/step - loss: 0.0040\n",
      "Epoch 3/50\n",
      "2368/2368 [==============================] - 406s 171ms/step - loss: 0.0014\n",
      "Epoch 4/50\n",
      "2368/2368 [==============================] - 3330s 1s/step - loss: 8.5621e-04\n",
      "Epoch 5/50\n",
      "2368/2368 [==============================] - 740s 312ms/step - loss: 5.8569e-04\n",
      "Epoch 6/50\n",
      "2368/2368 [==============================] - 154s 65ms/step - loss: 4.1090e-04\n",
      "Epoch 7/50\n",
      "2368/2368 [==============================] - 678s 286ms/step - loss: 3.0517e-04\n",
      "Epoch 8/50\n",
      "2368/2368 [==============================] - 132s 56ms/step - loss: 2.4724e-04\n",
      "Epoch 9/50\n",
      "2368/2368 [==============================] - 146s 62ms/step - loss: 2.0835e-04\n",
      "Epoch 10/50\n",
      "2368/2368 [==============================] - 204s 86ms/step - loss: 1.8715e-04\n",
      "Epoch 11/50\n",
      "2368/2368 [==============================] - 279s 118ms/step - loss: 1.6944e-04\n",
      "Epoch 12/50\n",
      "2368/2368 [==============================] - 479s 202ms/step - loss: 1.5922e-04\n",
      "Epoch 13/50\n",
      "2368/2368 [==============================] - 298s 126ms/step - loss: 1.5475e-04\n",
      "Epoch 14/50\n",
      "2368/2368 [==============================] - 335s 141ms/step - loss: 1.4854e-04\n",
      "Epoch 15/50\n",
      "2368/2368 [==============================] - 486s 206ms/step - loss: 1.4405e-04\n",
      "Epoch 16/50\n",
      "2368/2368 [==============================] - 607s 256ms/step - loss: 1.4048e-04\n",
      "Epoch 17/50\n",
      "2368/2368 [==============================] - 614s 259ms/step - loss: 1.3586e-04\n",
      "Epoch 18/50\n",
      "2368/2368 [==============================] - 625s 264ms/step - loss: 1.3435e-04\n",
      "Epoch 19/50\n",
      "2368/2368 [==============================] - 419s 177ms/step - loss: 1.2922e-04\n",
      "Epoch 20/50\n",
      "2368/2368 [==============================] - 516s 218ms/step - loss: 1.2854e-04\n",
      "Epoch 21/50\n",
      " 825/2368 [=========>....................] - ETA: 11:20 - loss: 1.2216e-04"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "epochs = 50\n",
    "\n",
    "# Define a ModelCheckpoint callback to save the model weights based on validation loss\n",
    "#checkpoint = ModelCheckpoint('best_weights.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# Fit the model to the data, using the ModelCheckpoint callback\n",
    "history = model.fit(generator, epochs=epochs, batch_size=1) #validation_data=(scaled_test,scaled_test), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de699997-b427-4a5c-8508-4a4262bf2226",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_per_epoch = model.history.history['loss']\n",
    "#val_loss_per_epoch = model.history.history['val_loss']\n",
    "plt.plot(range(len(loss_per_epoch)),loss_per_epoch);\n",
    "#plt.plot(range(len(val_loss_per_epoch)), val_loss_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027cad75-5bc7-4aed-9b61-e253e7ac61c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_train_batch = scaled_train[-n_input:] \n",
    "# take the last n_input month of values, to make \n",
    "# predictions on the 1st test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c36497-2d27-49ee-99d0-5f17aeb01b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_train_batch = last_train_batch.reshape((1, n_input, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2827ecc5-7f07-4bce-9367-9e7300026262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.predict(last_train_batch)\n",
    "\n",
    "y_pred = model.predict(generator)\n",
    "\n",
    "st = scaled_train.shape[0]\n",
    "yp = y_pred.shape[0]\n",
    "c = st - yp\n",
    "# Note: predictions start after 'n_input' numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e934267-9323-443b-bf02-7ee1ed36d242",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(c, st), y_pred, label='predict') \n",
    "plt.plot(scaled_train, label='train')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e33c08-0dce-4a30-b805-40be960c148d",
   "metadata": {},
   "source": [
    "#### Comment on plot:\n",
    "\n",
    "The above plot shows how well our model fits with the training data. As the orange and blue lines almost completely overlap, we can conclude that the model accurately fits with the data. This is a necessary check, as our model will have no chance of predicting future sunspot numbers if it cannot successfully predict the training values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a534f6-9e5e-44f1-af70-7b379daee63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_predictions = []\n",
    "\n",
    "first_eval_batch = scaled_train[-n_input:]\n",
    "current_batch = first_eval_batch.reshape((1, n_input, n_features))\n",
    "\n",
    "for i in range(len(validation_data)):\n",
    "    \n",
    "    # get the prediction value for the first batch\n",
    "    current_pred = model.predict(current_batch)[0]\n",
    "    \n",
    "    # append the prediction into the array\n",
    "    validation_predictions.append(current_pred) \n",
    "    \n",
    "    # use the prediction to update the batch and remove the first value\n",
    "    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787881a8-d5ab-42b6-8403-302b605fe40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_predictions\n",
    "# NOTE: these predictions are in the range 0-1\n",
    "# we need to convert it back "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c1f186-6cc9-4993-83df-16cae238fc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_predictions = scaler.inverse_transform(validation_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee137c3-91f5-454e-a4cf-fb9e73275afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data['Predictions'] = true_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f1e22-3adb-426a-82e3-f45ce5e004a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data.plot(figsize=(14,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb01a206-0ccc-419c-bb67-ba52320f2a53",
   "metadata": {},
   "source": [
    "#### Comment on plot:\n",
    "\n",
    "The predictions for future sunspot number seem to have a period which is close to the observed period (but not perfect), and the amplitude is still too high. I can try running again with more epochs or more neurons and see what happens.\n",
    "\n",
    "**Edit**: run with 300 neurons produced a similar result to one with 200 neurons. Next I will try running with 200 neurons again, but for 100 epochs.\n",
    "\n",
    "**Edit 2**: run with 200 neurons for 87 epochs produced results with a smaller amplitude, but the timing of the peaks were incorrect.\n",
    "\n",
    "**Edit 3**: run with 300 neurons for 78 epochs --> fitting not appropriate, previous attempt was the best."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
