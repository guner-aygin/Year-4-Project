{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "851454bf-b1d4-454b-bd70-33905655e7b4",
   "metadata": {},
   "source": [
    "# Autoregressive LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6830fc40-731b-4884-aa83-710f31a9fc79",
   "metadata": {},
   "source": [
    "This example follows directly from the **TF** tutorial, which can be found at: https://www.tensorflow.org/tutorials/structured_data/time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b324c1c4-561d-41d5-92b7-79c8e16793ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b36628-c2ba-402f-8505-994f705f2562",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f974dd67-aa23-4e02-a5d9-1187ab6bca3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74783, 2)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../Data/Savitzky-Golay Data/SVG_poly1.csv')\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "print(df.shape)\n",
    "\n",
    "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
    "\n",
    "df.head()\n",
    "num_features = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12c74c84-4a7b-4e2b-9df4-3740daaf038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_time = 65000\n",
    "skips = 20\n",
    "train_df = df[:split_time:skips]\n",
    "val_df = df[split_time::skips]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4c52f4-9696-4dcf-9621-3436930c5b54",
   "metadata": {},
   "source": [
    "### Loss & Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bdae859-f3c7-49d7-89e8-9298e47f4229",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.MeanAbsoluteError()\n",
    "metric = ['mae']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b43ecb8-cf52-4f83-8a1a-86feb0ebabdd",
   "metadata": {},
   "source": [
    "## Data Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "543abc67-82b0-424f-abfe-1ea775d7ab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "    def __init__(self, input_width, label_width, shift,\n",
    "               train_df=train_df, val_df=val_df,\n",
    "               label_columns=None):\n",
    "        # Store the raw data.\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "\n",
    "        # Work out the label column indices.\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in\n",
    "                                        enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in\n",
    "                               enumerate(train_df.columns)}\n",
    "\n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "\n",
    "        self.total_window_size = input_width + shift\n",
    "\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Label indices: {self.label_indices}',\n",
    "            f'Label column name(s): {self.label_columns}'])\n",
    "    \n",
    "def split_window(self, features):\n",
    "    inputs = features[:, self.input_slice, :]\n",
    "    labels = features[:, self.labels_slice, :]\n",
    "    if self.label_columns is not None:\n",
    "        labels = tf.stack(\n",
    "            [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "            axis=-1)\n",
    "\n",
    "    # Slicing doesn't preserve static shape information, so set the shapes\n",
    "    # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "    inputs.set_shape([None, self.input_width, None])\n",
    "    labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "    return inputs, labels\n",
    "\n",
    "WindowGenerator.split_window = split_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31a94ba9-97d4-4480-8bcb-c734b528368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(self, model=None, plot_col='Sunspot_Number', max_subplots=3):\n",
    "    inputs, labels = self.example\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plot_col_index = self.column_indices[plot_col]\n",
    "    max_n = min(max_subplots, len(inputs))\n",
    "    for n in range(max_n):\n",
    "        plt.subplot(max_n, 1, n+1)\n",
    "        plt.ylabel(f'{plot_col} [normed]')\n",
    "        plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "                 label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "        if self.label_columns:\n",
    "            label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "        else:\n",
    "            label_col_index = plot_col_index\n",
    "\n",
    "        if label_col_index is None:\n",
    "            continue\n",
    "\n",
    "        plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                    edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "        \n",
    "        if model is not None:\n",
    "            predictions = model(inputs)\n",
    "            if predictions.shape[-1] == 1:\n",
    "                predictions = tf.squeeze(predictions, axis=-1)\n",
    "\n",
    "            if len(predictions.shape) == 2:\n",
    "                plt.scatter(self.label_indices, predictions[n, :],\n",
    "                            marker='X', edgecolors='k', label='Predictions',\n",
    "                            c='#ff7f0e', s=64)\n",
    "            else:\n",
    "                plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                            marker='X', edgecolors='k', label='Predictions',\n",
    "                            c='#ff7f0e', s=64)\n",
    "\n",
    "        if n == 0:\n",
    "            plt.legend()\n",
    "\n",
    "    plt.xlabel('Time')\n",
    "\n",
    "WindowGenerator.plot = plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5932139b-36d4-4876-98df-670678d367ad",
   "metadata": {},
   "source": [
    "## Create tf.data.Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96522c2b-94e3-49cb-af6e-9909fc797d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(self, data):\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=None,\n",
    "      sequence_length=self.total_window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=True,\n",
    "      batch_size=32,)\n",
    "\n",
    "    ds = ds.map(self.split_window)\n",
    "\n",
    "    return ds\n",
    "\n",
    "WindowGenerator.make_dataset = make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48c544ee-5593-4c2d-aada-6211fe574262",
   "metadata": {},
   "outputs": [],
   "source": [
    "@property\n",
    "def train(self):\n",
    "    return self.make_dataset(self.train_df)\n",
    "\n",
    "@property\n",
    "def val(self):\n",
    "    return self.make_dataset(self.val_df)\n",
    "\n",
    "@property\n",
    "def example(self):\n",
    "    \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "    result = getattr(self, '_example', None)\n",
    "    if result is None:\n",
    "        # No example batch was found, so get one from the `.train` dataset\n",
    "        result = next(iter(self.train))\n",
    "        # And cache it for next time\n",
    "        self._example = result\n",
    "    return result\n",
    "\n",
    "WindowGenerator.train = train\n",
    "WindowGenerator.val = val\n",
    "WindowGenerator.example = example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf85ca52-69b6-4548-a5cd-dcfb083829ff",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e169778b-d787-4e6d-9a62-0dcd703408fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total window size: 25\n",
       "Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
       "Label indices: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
       "Label column name(s): ['Sunspot_Number']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wide_window = WindowGenerator(\n",
    "    input_width=24, label_width=24, shift=1,\n",
    "    label_columns=['Sunspot_Number'])\n",
    "\n",
    "wide_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "facd8e59-d3ff-48f1-ada1-e06efc049f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 500\n",
    "\n",
    "def compile_and_fit(model, window, patience=15):\n",
    "    \n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "\n",
    "    model.compile(loss=loss,\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=metric)\n",
    "\n",
    "    history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                      validation_data=window.val,\n",
    "                      callbacks=[early_stopping])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b64278b6-b8dc-432e-8c18-7ce20ed3e247",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=5,\n",
    "                          strides=1, padding='causal',\n",
    "                          activation='relu'),\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(num_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cf0334b-115f-46e3-9ff5-56fd438b5a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 37ms/step - loss: 6.1697 - mae: 6.1697\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'val_performance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m history \u001b[38;5;241m=\u001b[39m compile_and_fit(lstm_model, wide_window)\n\u001b[1;32m      4\u001b[0m IPython\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mclear_output()\n\u001b[0;32m----> 5\u001b[0m \u001b[43mval_performance\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLSTM\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m lstm_model\u001b[38;5;241m.\u001b[39mevaluate(wide_window\u001b[38;5;241m.\u001b[39mval)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39msemilogx(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]);\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_performance' is not defined"
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "history = compile_and_fit(lstm_model, wide_window)\n",
    "\n",
    "IPython.display.clear_output()\n",
    "val_performance['LSTM'] = lstm_model.evaluate(wide_window.val)\n",
    "plt.semilogx(history.history[\"loss\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbb579c-1cc0-4f26-bf88-6d959e5d7bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
