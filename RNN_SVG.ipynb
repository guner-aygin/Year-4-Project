{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec39fb3f-0be8-45db-85a3-b1212b10f18d",
   "metadata": {},
   "source": [
    "# RNN for Smoothed Sunspot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e262a69-e869-463a-8a39-d05a937e127c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 20:43:10.922050: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82445405-11db-4268-890e-ade5526d5fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/SVG_poly1.csv') # importing data for SVG polyorder = 1\n",
    "X = ((df.Year).values).reshape(-1,1)\n",
    "y = (df.Sunspot_Number).values\n",
    "yerr = np.zeros(len(X))\n",
    "\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True) \n",
    "# removes the unnecessary column\n",
    "df.set_index(\"Year\", inplace=True)\n",
    "\n",
    "\n",
    "#df.head(), df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788363be-7f60-4c6c-8099-79a2e9a7ee8c",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "201ade13-5a48-4c1b-bf5f-7d6b57ae90f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 70000\n",
    "skips = 28 # 1 data point per luna cycle\n",
    "train_data = df.iloc[:limit:skips]\n",
    "validation_data = df.iloc[limit::skips]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19c907a1-00a2-46da-a5b3-8ddb4f72204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfc70b68-7400-4023-943c-84ebfa249940",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(train_data)\n",
    "scaled_train = scaler.transform(train_data)\n",
    "scaled_test = scaler.transform(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46b360bd-f40b-484c-b486-eb08f1d529c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0f8c7d9-c1f9-4767-b179-73c76a68df3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generator\n",
    "n_input = 11 * 12 # 11 years \n",
    "n_features = 1 # we are only using 1 timeseries to make our predictions\n",
    "generator = TimeseriesGenerator(scaled_train, scaled_train, length=n_input, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "304f2642-1efd-4ffe-ac4d-a0a461eb3d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the Array: \n",
      "[0.1263682  0.12394294 0.12151768 0.11909242 0.11666716 0.1142419\n",
      " 0.11181664 0.10939138 0.10696612 0.10454086 0.1021156  0.09969034\n",
      " 0.09726508 0.09483982 0.09241456 0.0899893  0.08756405 0.08513879\n",
      " 0.08271353 0.08028827 0.07786301 0.07543775 0.07301249 0.07058723\n",
      " 0.06816197 0.06573671 0.06331145 0.06201998 0.060503   0.06106645\n",
      " 0.05982108 0.05698361 0.05190677 0.04829202 0.04698308 0.04441722\n",
      " 0.04254772 0.03949642 0.03890696 0.03753446 0.0356534  0.03475477\n",
      " 0.03442826 0.03293728 0.0313914  0.02761195 0.02417635 0.02171451\n",
      " 0.01897816 0.0175941  0.01513803 0.01284667 0.01183246 0.01105518\n",
      " 0.00859912 0.00783051 0.00666605 0.00502193 0.00388925 0.00271612\n",
      " 0.00228847 0.         0.00187817 0.00339804 0.00306864 0.00230581\n",
      " 0.00194174 0.00373033 0.00564895 0.00566051 0.00605059 0.00783051\n",
      " 0.01033281 0.0134419  0.01606267 0.0174294  0.01689195 0.01697286\n",
      " 0.01930756 0.0208361  0.02274316 0.02533504 0.0269127  0.02994088\n",
      " 0.03311932 0.03818459 0.04405314 0.04904329 0.05130287 0.05792558\n",
      " 0.061549   0.06650447 0.07124323 0.0745777  0.08281852 0.08828255\n",
      " 0.09551205 0.10029704 0.10890772 0.11436018 0.12078929 0.12759115\n",
      " 0.13439012 0.13900463 0.14249802 0.14573714 0.15166926 0.15843355\n",
      " 0.16379933 0.17316127 0.18276882 0.19517051 0.20216307 0.21303911\n",
      " 0.21850313 0.22150242 0.22689998 0.23099728 0.23325686 0.23512347\n",
      " 0.23764021 0.24819262 0.25942696 0.26435642 0.27268104 0.27954647\n",
      " 0.2852272  0.28919158 0.2941615  0.29910541 0.30374015 0.30397709]\n",
      "Predict this y: \n",
      " [[0.30774499]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 132, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y = generator[0]\n",
    "print(f'Given the Array: \\n{X.flatten()}')\n",
    "print(f'Predict this y: \\n {y}')\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fec8f90-8c99-4347-98aa-e9213d8af1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c01a358a-bea8-4a9b-8f29-697433c8072c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 20:43:30.774366: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100)               40800     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,901\n",
      "Trainable params: 40,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential() # adds layers in a sequence\n",
    "model.add(LSTM(100, activation='relu', input_shape=(n_input, n_features))) # maybe try elu?\n",
    "# 100 neurons\n",
    "model.add(Dense(1))\n",
    "# 1 layer\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48d6394a-eaa0-4232-a9a9-d4e93c3bf307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2367/2368 [============================>.] - ETA: 0s - loss: 1.5720e-04"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'numpy.bool_'>, <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# fit model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaled_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlp/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlp/lib/python3.8/site-packages/keras/engine/data_adapter.py:1083\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1080\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ALL_ADAPTER_CLS \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcan_handle(x, y)]\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m adapter_cls:\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[0;32m-> 1083\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1084\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find data adapter that can handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1085\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(_type_name(x), _type_name(y))\n\u001b[1;32m   1086\u001b[0m     )\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(adapter_cls) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1089\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData adapters should be mutually exclusive for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1090\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhandling inputs. Found multiple adapters \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1091\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001b[1;32m   1092\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'numpy.bool_'>, <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "epochs = 10\n",
    "model.fit(generator, epochs=epochs, validation_data=scaled_test.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "590c6a21-b095-4189-a820-9635186a9285",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 12\u001b[0m\n\u001b[1;32m      2\u001b[0m es_callback \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      4\u001b[0m modelckpt_callback \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[1;32m      5\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     filepath\u001b[38;5;241m=\u001b[39mpath_checkpoint,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelckpt_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlp/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlp/lib/python3.8/site-packages/pandas/core/generic.py:1527\u001b[0m, in \u001b[0;36mNDFrame.__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__nonzero__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1528\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe truth value of a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is ambiguous. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1529\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1530\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "'''\n",
    "path_checkpoint = \"LSTM_model_checkpoint.h5\"\n",
    "es_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0.0, patience=5)\n",
    "\n",
    "modelckpt_callback = keras.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    filepath=path_checkpoint,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_data,\n",
    "    callbacks=[es_callback, modelckpt_callback],\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de699997-b427-4a5c-8508-4a4262bf2226",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_per_epoch = model.history.history['loss']\n",
    "val_loss_per_epoch = model.history.history['val_loss']\n",
    "plt.plot(range(len(loss_per_epoch)),loss_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027cad75-5bc7-4aed-9b61-e253e7ac61c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_train_batch = scaled_train[-n_input:] \n",
    "# take the last n_input month of values, to make \n",
    "# predictions on the 1st test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c36497-2d27-49ee-99d0-5f17aeb01b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_train_batch = last_train_batch.reshape((1, n_input, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2827ecc5-7f07-4bce-9367-9e7300026262",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(last_train_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a534f6-9e5e-44f1-af70-7b379daee63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = []\n",
    "\n",
    "first_eval_batch = scaled_train[-n_input:]\n",
    "current_batch = first_eval_batch.reshape((1, n_input, n_features))\n",
    "\n",
    "for i in range(len(test)):\n",
    "    \n",
    "    # get the prediction value for the first batch\n",
    "    current_pred = model.predict(current_batch)[0]\n",
    "    \n",
    "    # append the prediction into the array\n",
    "    test_predictions.append(current_pred) \n",
    "    \n",
    "    # use the prediction to update the batch and remove the first value\n",
    "    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787881a8-d5ab-42b6-8403-302b605fe40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions\n",
    "# NOTE: these predictions are in the range 0-1\n",
    "# we need to convert it back "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c1f186-6cc9-4993-83df-16cae238fc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_predictions = scaler.inverse_transform(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee137c3-91f5-454e-a4cf-fb9e73275afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Predictions'] = true_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f1e22-3adb-426a-82e3-f45ce5e004a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.plot(figsize=(14,5));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
